{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f0e285",
   "metadata": {},
   "source": [
    "# Ride analysis of cycling fit files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ea822",
   "metadata": {},
   "source": [
    "## Import and chores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2a67f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project root added to sys.path: C:\\Users\\betti\\OneDrive\\Dokumente\\lukas_github\\gpxfun\n"
     ]
    }
   ],
   "source": [
    "# --- Fix import paths so `import gpxfun.*` works from inside notebooks/ ---\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Resolve the absolute path of the project root (one level up from 'notebooks/')\n",
    "project_root = Path(os.getcwd()).resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"‚úÖ Project root added to sys.path:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d559d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../data/rides/Blind_passenger_üêà.fit')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library\n",
    "from pathlib import Path  # convenient, cross-platform path handling\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd       # tabular data\n",
    "import numpy as np        # fast numeric ops\n",
    "\n",
    "# Geometry / CRS\n",
    "import geopandas as gpd   # geospatial dataframes\n",
    "from pyproj import Geod   # accurate geodesic distances using ellipsoid\n",
    "\n",
    "# Local project modules\n",
    "from gpxfun.io_fit import parse_fit                 # your FIT ‚Üí DataFrame parser\n",
    "from gpxfun.geo_utils import build_line_gdf, pick_utm_crs, to_projected  # helpers\n",
    "\n",
    "# Project paths (relative to notebooks/)\n",
    "RIDES_DIR = Path(\"../data/rides\")   # folder with your .fit files\n",
    "OUT_DIR   = Path(\"../outputs\")      # where we‚Äôll save QA tables and maps\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)  # create outputs/ if it doesn't exist\n",
    "\n",
    "# Find a .fit to work with (first one for now)\n",
    "fits = sorted(RIDES_DIR.rglob(\"*.fit\"))   # recursively list .fit files\n",
    "assert fits, f\"No .fit files found under {RIDES_DIR.resolve()}\"  # hard-stop if none\n",
    "fit_path = fits[0]  # pick the first file deterministically\n",
    "fit_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca5bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def query_overpass(bbox: tuple[float,float,float,float], filter_expr: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Query Overpass API directly and return a GeoDataFrame.\n",
    "    bbox = (south, west, north, east)\n",
    "    filter_expr example: way[\"bridge\"=\"yes\"]\n",
    "    \"\"\"\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    south, west, north, east = bbox\n",
    "\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    (\n",
    "      {filter_expr}({south},{west},{north},{east});\n",
    "    );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"‚è≥ Sending query to Overpass...\")\n",
    "    r = requests.post(overpass_url, data={\"data\": query}, timeout=40)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    data = r.json()\n",
    "    elements = data.get(\"elements\", [])\n",
    "    print(f\"‚úÖ Received {len(elements)} elements\")\n",
    "\n",
    "    if not elements:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\"], geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    features = []\n",
    "    for el in elements:\n",
    "        if \"geometry\" not in el:\n",
    "            continue\n",
    "        coords = [(p[\"lon\"], p[\"lat\"]) for p in el[\"geometry\"]]\n",
    "        try:\n",
    "            geom = shape({\"type\": \"LineString\", \"coordinates\": coords})\n",
    "            features.append(geom)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return gpd.GeoDataFrame(geometry=features, crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e1ea",
   "metadata": {},
   "source": [
    "## File ingestion and basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49ce46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>enhanced_altitude</th>\n",
       "      <th>enhanced_speed</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>power</th>\n",
       "      <th>speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167.6</td>\n",
       "      <td>319.2</td>\n",
       "      <td>167.6</td>\n",
       "      <td>8.28</td>\n",
       "      <td>23.363388</td>\n",
       "      <td>121.319783</td>\n",
       "      <td>0</td>\n",
       "      <td>8.28</td>\n",
       "      <td>24</td>\n",
       "      <td>2025-10-11 05:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.2</td>\n",
       "      <td>327.7</td>\n",
       "      <td>167.2</td>\n",
       "      <td>8.40</td>\n",
       "      <td>23.363436</td>\n",
       "      <td>121.319847</td>\n",
       "      <td>0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-10-11 05:20:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166.8</td>\n",
       "      <td>335.7</td>\n",
       "      <td>166.8</td>\n",
       "      <td>8.34</td>\n",
       "      <td>23.363483</td>\n",
       "      <td>121.319908</td>\n",
       "      <td>0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-10-11 05:20:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   altitude  distance  enhanced_altitude  enhanced_speed        lat  \\\n",
       "0     167.6     319.2              167.6            8.28  23.363388   \n",
       "1     167.2     327.7              167.2            8.40  23.363436   \n",
       "2     166.8     335.7              166.8            8.34  23.363483   \n",
       "\n",
       "          lon  power  speed  temperature           timestamp  \n",
       "0  121.319783      0   8.28           24 2025-10-11 05:20:18  \n",
       "1  121.319847      0   8.40           23 2025-10-11 05:20:19  \n",
       "2  121.319908      0   8.34           23 2025-10-11 05:20:20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 17660\n",
      "columns: ['altitude', 'distance', 'enhanced_altitude', 'enhanced_speed', 'lat', 'lon', 'power', 'speed', 'temperature', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "# Parse the selected .fit into a raw DataFrame\n",
    "raw = parse_fit(str(fit_path))  # returns columns like lat, lon, timestamp, altitude, hr, cadence, speed, ...\n",
    "\n",
    "# Basic inspection to understand fields and size\n",
    "display(raw.head(3))         # show first rows to confirm expected columns\n",
    "print(\"rows:\", len(raw))     # total record count\n",
    "print(\"columns:\", list(raw.columns))  # what sensors we got\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b215b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>ele</th>\n",
       "      <th>speed_m_s</th>\n",
       "      <th>temperature</th>\n",
       "      <th>power</th>\n",
       "      <th>time</th>\n",
       "      <th>ride_id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.363388</td>\n",
       "      <td>121.319783</td>\n",
       "      <td>167.6</td>\n",
       "      <td>8.28</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-11 05:20:18</td>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.363436</td>\n",
       "      <td>121.319847</td>\n",
       "      <td>167.2</td>\n",
       "      <td>8.40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-11 05:20:19</td>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.363483</td>\n",
       "      <td>121.319908</td>\n",
       "      <td>166.8</td>\n",
       "      <td>8.34</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-11 05:20:20</td>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon    ele  speed_m_s  temperature  power  \\\n",
       "0  23.363388  121.319783  167.6       8.28           24      0   \n",
       "1  23.363436  121.319847  167.2       8.40           23      0   \n",
       "2  23.363483  121.319908  166.8       8.34           23      0   \n",
       "\n",
       "                 time            ride_id  seq  \n",
       "0 2025-10-11 05:20:18  Blind_passenger_üêà    0  \n",
       "1 2025-10-11 05:20:19  Blind_passenger_üêà    1  \n",
       "2 2025-10-11 05:20:20  Blind_passenger_üêà    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned rows: 17660\n",
      "columns: ['lat', 'lon', 'ele', 'speed_m_s', 'temperature', 'power', 'time', 'ride_id', 'seq']\n"
     ]
    }
   ],
   "source": [
    "# --- Select the best available core fields ---\n",
    "alt_col = \"enhanced_altitude\" if \"enhanced_altitude\" in raw.columns else \"altitude\"  # elevation in meters\n",
    "spd_col = \"enhanced_speed\" if \"enhanced_speed\" in raw.columns else \"speed\"           # speed in m/s\n",
    "\n",
    "# --- Build column list, making sure temperature & HR are included if present ---\n",
    "keep_cols = [\"timestamp\", \"lat\", \"lon\"]\n",
    "for col in [alt_col, spd_col, \"temperature\", \"heart_rate\", \"power\"]:\n",
    "    if col in raw.columns:\n",
    "        keep_cols.append(col)\n",
    "\n",
    "# --- Work on a clean copy ---\n",
    "pts = raw[keep_cols].copy()\n",
    "\n",
    "# --- Rename to our standard schema (for consistency across devices) ---\n",
    "rename_map = {\n",
    "    alt_col: \"ele\",          # elevation\n",
    "    spd_col: \"speed_m_s\",    # meters per second\n",
    "}\n",
    "pts = pts.rename(columns=rename_map)\n",
    "\n",
    "# --- Time handling ---\n",
    "pts[\"time\"] = pd.to_datetime(pts[\"timestamp\"], errors=\"coerce\")  # ensure datetime\n",
    "pts = pts.drop(columns=[\"timestamp\"], errors=\"ignore\")           # drop redundant field\n",
    "pts = pts.sort_values(\"time\").reset_index(drop=True)             # chronological order\n",
    "\n",
    "# --- Drop rows missing mandatory spatial fields ---\n",
    "pts = pts.dropna(subset=[\"lat\", \"lon\", \"time\"])\n",
    "\n",
    "# --- Add identifiers ---\n",
    "ride_id = Path(fit_path).stem  # use filename as stable ride id\n",
    "pts[\"ride_id\"] = ride_id\n",
    "pts[\"seq\"] = np.arange(len(pts))  # sequential index for joining and plotting\n",
    "\n",
    "# --- Display structure ---\n",
    "display(pts.head(3))\n",
    "print(\"‚úÖ Cleaned rows:\", len(pts))\n",
    "print(\"columns:\", list(pts.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc340e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ride_id = Blind_passenger_üêà  |  total points = 17660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>0</td>\n",
       "      <td>23.363388</td>\n",
       "      <td>121.319783</td>\n",
       "      <td>2025-10-11 05:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>1</td>\n",
       "      <td>23.363436</td>\n",
       "      <td>121.319847</td>\n",
       "      <td>2025-10-11 05:20:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>2</td>\n",
       "      <td>23.363483</td>\n",
       "      <td>121.319908</td>\n",
       "      <td>2025-10-11 05:20:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ride_id  seq        lat         lon                time\n",
       "0  Blind_passenger_üêà    0  23.363388  121.319783 2025-10-11 05:20:18\n",
       "1  Blind_passenger_üêà    1  23.363436  121.319847 2025-10-11 05:20:19\n",
       "2  Blind_passenger_üêà    2  23.363483  121.319908 2025-10-11 05:20:20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Each ride (i.e., each FIT file) gets a stable unique identifier\n",
    "from pathlib import Path\n",
    "\n",
    "# Derive a readable ride_id from the filename (e.g. \"2025-08-05_morningride\")\n",
    "ride_id = Path(fit_path).stem\n",
    "\n",
    "# Attach to all rows ‚Äî allows grouping, joins, exports later\n",
    "pts[\"ride_id\"] = ride_id\n",
    "\n",
    "# Add a sequential index to preserve order and enable joins\n",
    "pts[\"seq\"] = np.arange(len(pts))  # 0, 1, 2, ...\n",
    "\n",
    "# Optionally preview ‚Äî useful for debugging when we process multiple rides later\n",
    "print(f\"‚úÖ ride_id = {ride_id}  |  total points = {len(pts)}\")\n",
    "display(pts.head(3)[[\"ride_id\", \"seq\", \"lat\", \"lon\", \"time\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b223dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>time</th>\n",
       "      <th>dist_m</th>\n",
       "      <th>dt_s</th>\n",
       "      <th>speed_m_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2025-10-11 05:20:18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-11 05:20:19</td>\n",
       "      <td>8.430018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-11 05:20:20</td>\n",
       "      <td>8.126881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-11 05:20:21</td>\n",
       "      <td>7.362914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-11 05:20:22</td>\n",
       "      <td>7.826308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-10-11 05:20:23</td>\n",
       "      <td>7.588110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2025-10-11 05:20:24</td>\n",
       "      <td>8.120929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-10-11 05:20:25</td>\n",
       "      <td>7.774852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2025-10-11 05:20:26</td>\n",
       "      <td>7.781720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2025-10-11 05:20:27</td>\n",
       "      <td>8.047837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq                time    dist_m  dt_s  speed_m_s\n",
       "0    0 2025-10-11 05:20:18  0.000000   NaN       8.28\n",
       "1    1 2025-10-11 05:20:19  8.430018   1.0       8.40\n",
       "2    2 2025-10-11 05:20:20  8.126881   1.0       8.34\n",
       "3    3 2025-10-11 05:20:21  7.362914   1.0       8.26\n",
       "4    4 2025-10-11 05:20:22  7.826308   1.0       8.06\n",
       "5    5 2025-10-11 05:20:23  7.588110   1.0       7.92\n",
       "6    6 2025-10-11 05:20:24  8.120929   1.0       7.84\n",
       "7    7 2025-10-11 05:20:25  7.774852   1.0       7.78\n",
       "8    8 2025-10-11 05:20:26  7.781720   1.0       7.80\n",
       "9    9 2025-10-11 05:20:27  8.047837   1.0       7.86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Distance/time metrics added ‚Äî total rows: 17660\n"
     ]
    }
   ],
   "source": [
    "# --- Geodesic distance & time delta computation ---\n",
    "from pyproj import Geod\n",
    "import numpy as np\n",
    "\n",
    "# Initialize geodesic calculator using WGS84 ellipsoid (accurate for Earth)\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "# Extract coordinates and timestamps as numpy arrays for vectorized math\n",
    "lat = pts[\"lat\"].values\n",
    "lon = pts[\"lon\"].values\n",
    "t  = pts[\"time\"].values.astype(\"datetime64[ns]\")  # nanosecond precision timestamps\n",
    "\n",
    "# Compute distance between consecutive GPS points (in meters)\n",
    "# geod.inv returns (azimuth_fwd, azimuth_back, distance_m)\n",
    "_, _, dist_m = geod.inv(lon[:-1], lat[:-1], lon[1:], lat[1:])\n",
    "\n",
    "# prepend 0 for the first row (no previous point)\n",
    "pts[\"dist_m\"] = np.r_[0.0, dist_m]\n",
    "\n",
    "# Compute time differences between points (seconds)\n",
    "# np.diff gives deltas; prepend NaN for first row\n",
    "pts[\"dt_s\"] = np.diff(t.astype(\"int64\") / 1e9, prepend=np.nan)  # 1e9 converts ns ‚Üí s\n",
    "\n",
    "# Derive geometric speed (m/s) as distance / time\n",
    "speed_geom = pts[\"dist_m\"] / pts[\"dt_s\"]\n",
    "\n",
    "# Clean up impossible values (dt=0 ‚Üí inf, NaN)\n",
    "speed_geom = np.where(np.isfinite(speed_geom), speed_geom, np.nan)\n",
    "\n",
    "# Combine: prefer device-recorded speed if valid, otherwise fallback to geometric one\n",
    "pts[\"speed_m_s\"] = np.where(\n",
    "    (pts[\"speed_m_s\"].notna()) & (pts[\"speed_m_s\"] > 0),\n",
    "    pts[\"speed_m_s\"],  # keep device-recorded\n",
    "    speed_geom,        # fallback\n",
    ")\n",
    "\n",
    "# Replace remaining NaNs/infinities with 0 (e.g., pauses)\n",
    "pts[\"speed_m_s\"] = np.nan_to_num(pts[\"speed_m_s\"], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# --- Quick sanity check ---\n",
    "display(pts[[\"seq\", \"time\", \"dist_m\", \"dt_s\", \"speed_m_s\"]].head(10))\n",
    "print(f\"‚úÖ Distance/time metrics added ‚Äî total rows: {len(pts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b892d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>heading_deg</th>\n",
       "      <th>speed_m_s</th>\n",
       "      <th>dist_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50.959505</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50.959505</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.430018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50.148555</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8.126881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.555034</td>\n",
       "      <td>8.26</td>\n",
       "      <td>7.362914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50.435775</td>\n",
       "      <td>8.06</td>\n",
       "      <td>7.826308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>47.808000</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.588110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>50.198796</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.120929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>53.260656</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.774852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>53.298392</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.781720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>58.421081</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.047837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq  heading_deg  speed_m_s    dist_m\n",
       "0    0    50.959505       8.28  0.000000\n",
       "1    1    50.959505       8.40  8.430018\n",
       "2    2    50.148555       8.34  8.126881\n",
       "3    3    48.555034       8.26  7.362914\n",
       "4    4    50.435775       8.06  7.826308\n",
       "5    5    47.808000       7.92  7.588110\n",
       "6    6    50.198796       7.84  8.120929\n",
       "7    7    53.260656       7.78  7.774852\n",
       "8    8    53.298392       7.80  7.781720\n",
       "9    9    58.421081       7.86  8.047837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Heading added ‚Äî 0¬∞=N, 90¬∞=E, 180¬∞=S, 270¬∞=W\n"
     ]
    }
   ],
   "source": [
    "# --- Bearing (direction of travel) computation ---\n",
    "from pyproj import Geod\n",
    "geod = Geod(ellps=\"WGS84\")  # reuse the same ellipsoid model\n",
    "\n",
    "# Compute forward azimuth (bearing) for each segment\n",
    "# geod.inv returns (az12, az21, dist_m); we only need az12 here\n",
    "az12, _, _ = geod.inv(lon[:-1], lat[:-1], lon[1:], lat[1:])\n",
    "\n",
    "# Normalize bearings to 0‚Äì360¬∞ and align them to the DataFrame\n",
    "bearing_deg = (az12 + 360) % 360\n",
    "pts[\"heading_deg\"] = np.r_[bearing_deg[0], bearing_deg]  # duplicate first bearing for length match\n",
    "\n",
    "# --- Quick peek ---\n",
    "display(pts[[\"seq\", \"heading_deg\", \"speed_m_s\", \"dist_m\"]].head(10))\n",
    "print(\"‚úÖ Heading added ‚Äî 0¬∞=N, 90¬∞=E, 180¬∞=S, 270¬∞=W\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02d3bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>elapsed_s</th>\n",
       "      <th>moving_time_s</th>\n",
       "      <th>total_km</th>\n",
       "      <th>elev_gain_m</th>\n",
       "      <th>avg_moving_kmh</th>\n",
       "      <th>avg_hr</th>\n",
       "      <th>avg_temp_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blind_passenger_üêà</td>\n",
       "      <td>2025-10-11 05:20:18</td>\n",
       "      <td>2025-10-11 14:42:27</td>\n",
       "      <td>33729.0</td>\n",
       "      <td>17422.0</td>\n",
       "      <td>115.261</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>23.65</td>\n",
       "      <td>None</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ride_id          start_time            end_time  elapsed_s  \\\n",
       "0  Blind_passenger_üêà 2025-10-11 05:20:18 2025-10-11 14:42:27    33729.0   \n",
       "\n",
       "   moving_time_s  total_km  elev_gain_m  avg_moving_kmh avg_hr  avg_temp_c  \n",
       "0        17422.0   115.261       1237.0           23.65   None        25.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ride_summary computed (raw elevation only)\n"
     ]
    }
   ],
   "source": [
    "# --- Ride summary (raw elevation) -------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Elevation gain ---------------------------------------------------------\n",
    "if \"ele\" in pts.columns:\n",
    "    delta_ele = pts[\"ele\"].diff().fillna(0.0)\n",
    "    elev_gain_m = float(delta_ele.clip(lower=0).sum())\n",
    "else:\n",
    "    elev_gain_m = np.nan\n",
    "\n",
    "# --- Distance & timing ------------------------------------------------------\n",
    "total_km = pts[\"dist_m\"].sum() / 1000.0\n",
    "moving_mask = pts[\"speed_m_s\"] >= 1.0\n",
    "moving_time_s = float(pts.loc[moving_mask, \"dt_s\"].fillna(0).clip(lower=0).sum())\n",
    "\n",
    "start_time = pts[\"time\"].min()\n",
    "end_time   = pts[\"time\"].max()\n",
    "elapsed_s  = (end_time - start_time).total_seconds()\n",
    "\n",
    "avg_moving_kmh = (pts.loc[moving_mask, \"dist_m\"].sum() / 1000.0) / (moving_time_s / 3600.0)\n",
    "\n",
    "# --- Environmental / physiological -----------------------------------------\n",
    "avg_hr = float(pts[\"heart_rate\"].mean()) if \"heart_rate\" in pts.columns else np.nan\n",
    "avg_temp_c = float(pts[\"temperature\"].mean()) if \"temperature\" in pts.columns else np.nan\n",
    "\n",
    "# --- Assemble summary table -------------------------------------------------\n",
    "summary = pd.DataFrame([{\n",
    "    \"ride_id\": pts[\"ride_id\"].iloc[0],\n",
    "    \"start_time\": start_time,\n",
    "    \"end_time\": end_time,\n",
    "    \"elapsed_s\": round(elapsed_s, 1),\n",
    "    \"moving_time_s\": round(moving_time_s, 1),\n",
    "    \"total_km\": round(total_km, 3),\n",
    "    \"elev_gain_m\": round(elev_gain_m, 1),\n",
    "    \"avg_moving_kmh\": round(avg_moving_kmh, 2),\n",
    "    \"avg_hr\": round(avg_hr, 1) if not np.isnan(avg_hr) else None,\n",
    "    \"avg_temp_c\": round(avg_temp_c, 1) if not np.isnan(avg_temp_c) else None,\n",
    "}])\n",
    "\n",
    "display(summary)\n",
    "print(\"‚úÖ ride_summary computed (raw elevation only)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c52db",
   "metadata": {},
   "source": [
    "## 2. Ride display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55749d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# --- Compute ride center for initial map view ---\n",
    "lat_center = pts[\"lat\"].mean()\n",
    "lon_center = pts[\"lon\"].mean()\n",
    "\n",
    "# --- Create a Folium map centered on your ride ---\n",
    "m = folium.Map(\n",
    "    location=[lat_center, lon_center],\n",
    "    zoom_start=11,\n",
    "    tiles=\"OpenStreetMap\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# --- Add the full ride trace as a polyline ---\n",
    "coords = list(zip(pts[\"lat\"], pts[\"lon\"]))\n",
    "folium.PolyLine(\n",
    "    coords,\n",
    "    color=\"red\",\n",
    "    weight=3,\n",
    "    opacity=0.9,\n",
    "    tooltip=f\"Ride: {pts['ride_id'].iloc[0]}\",\n",
    ").add_to(m)\n",
    "\n",
    "# --- Optional: add start & end markers ---\n",
    "folium.Marker(\n",
    "    location=[pts[\"lat\"].iloc[0], pts[\"lon\"].iloc[0]],\n",
    "    popup=\"Start\",\n",
    "    icon=folium.Icon(color=\"green\", icon=\"play\"),\n",
    ").add_to(m)\n",
    "\n",
    "folium.Marker(\n",
    "    location=[pts[\"lat\"].iloc[-1], pts[\"lon\"].iloc[-1]],\n",
    "    popup=\"End\",\n",
    "    icon=folium.Icon(color=\"red\", icon=\"stop\"),\n",
    ").add_to(m)\n",
    "\n",
    "# --- Optional: add a minimap for orientation ---\n",
    "plugins.MiniMap(toggle_display=True).add_to(m)\n",
    "\n",
    "# --- Display the map interactively ---\n",
    "m.save(\"ride_map.html\")\n",
    "import webbrowser\n",
    "webbrowser.open(\"ride_map.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d44a0",
   "metadata": {},
   "source": [
    "## Advanced OSM Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd2cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ride_id                                           geometry\n",
      "0        0  LINESTRING (121.31978 23.36339, 121.31985 23.3...\n",
      "Chosen UTM CRS: EPSG:32651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (328256.182 2584746.46, 328262.791 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id                                           geometry\n",
       "0        0  LINESTRING (328256.182 2584746.46, 328262.791 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpxfun.geo_utils import build_line_gdf, pick_utm_crs, to_projected\n",
    "\n",
    "# Build LineString from your ride points (EPSG:4326)\n",
    "gdf_line = build_line_gdf(pts)\n",
    "print(gdf_line)\n",
    "\n",
    "# Choose the best local UTM projection (for accurate meter-based ops)\n",
    "utm_crs = pick_utm_crs(gdf_line)\n",
    "print(\"Chosen UTM CRS:\", utm_crs)\n",
    "\n",
    "# Project to meters CRS (required for buffering and OSM overlays)\n",
    "gdf_line_p = to_projected(gdf_line, utm_crs)\n",
    "gdf_line_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43527478",
   "metadata": {},
   "source": [
    "## Query overpass for bridges and tunnels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42cfddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ride 115.2 km ‚Üí 3 chunks\n",
      "\n",
      "--- Chunk 1/3 ---\n",
      "lon[121.316,121.443] lat[23.362,23.629]\n",
      "‚è≥ [bridges] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚ö†Ô∏è [bridges] HTTP 504: Gateway Timeout\n",
      "‚è≥ [bridges] Attempt 2 via https://overpass.kumi.systems/api/interpreter ...\n",
      "‚úÖ [bridges] Success (139 features) ‚Äî cached as bridges_chunk_01.geojson\n",
      "‚è≥ [tunnels] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚úÖ [tunnels] Success (15 features) ‚Äî cached as tunnels_chunk_01.geojson\n",
      "\n",
      "--- Chunk 2/3 ---\n",
      "lon[121.434,121.562] lat[23.599,23.747]\n",
      "‚è≥ [bridges] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚úÖ [bridges] Success (122 features) ‚Äî cached as bridges_chunk_02.geojson\n",
      "‚è≥ [tunnels] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚úÖ [tunnels] Success (3 features) ‚Äî cached as tunnels_chunk_02.geojson\n",
      "\n",
      "--- Chunk 3/3 ---\n",
      "lon[121.552,121.612] lat[23.744,23.986]\n",
      "‚è≥ [bridges] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚úÖ [bridges] Success (132 features) ‚Äî cached as bridges_chunk_03.geojson\n",
      "‚è≥ [tunnels] Attempt 1 via https://overpass-api.de/api/interpreter ...\n",
      "‚ö†Ô∏è [tunnels] HTTP 429: Too Many Requests\n",
      "‚è≥ [tunnels] Attempt 2 via https://overpass.kumi.systems/api/interpreter ...\n",
      "‚úÖ [tunnels] Success (12 features) ‚Äî cached as tunnels_chunk_03.geojson\n",
      "‚ÑπÔ∏è Removed 2 duplicate geometries\n",
      "‚ÑπÔ∏è Removed 1 duplicate geometries\n",
      "\n",
      "‚úÖ Bridges in 25 m corridor: 68 | tunnels: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, time, folium, os\n",
    "from shapely.geometry import LineString, box\n",
    "from folium import plugins\n",
    "\n",
    "# =============================================================================\n",
    "# PARAMETERS\n",
    "# =============================================================================\n",
    "CHUNK_LEN_KM     = 40       # segment length per Overpass query (~10 km)\n",
    "SEARCH_RADIUS_M  = 25       # buffer width around route (corridor width)\n",
    "OVERLAP_M        = 200      # overlap between chunks (prevents gaps)\n",
    "END_PAD_M        = 100      # pad beyond last ride point\n",
    "\n",
    "# Overpass configuration\n",
    "OVERPASS_MIRRORS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://lz4.overpass-api.de/api/interpreter\",\n",
    "]\n",
    "OVERPASS_TIMEOUT = 60       # per request (s)\n",
    "INITIAL_BACKOFF  = 5        # starting delay (s)\n",
    "MAX_BACKOFF      = 300      # max delay (s)\n",
    "MAX_WAIT_MIN     = 45       # abort after this many minutes\n",
    "\n",
    "# Map rendering\n",
    "MAP_ZOOM_START   = 11\n",
    "MAP_TILE_STYLE   = \"OpenStreetMap\"\n",
    "MAP_SAVE_PATH    = \"ride_bridges_tunnels_final.html\"\n",
    "\n",
    "# Cache\n",
    "CACHE_DIR        = \"outputs/overpass_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def query_overpass_until_success(bbox, query_str, cache_name, label=\"\"):\n",
    "    \"\"\"Query Overpass API with mirror rotation, caching, and retry-until-success logic.\"\"\"\n",
    "    cache_path = os.path.join(CACHE_DIR, cache_name)\n",
    "\n",
    "    # --- Skip if cached ---\n",
    "    if os.path.exists(cache_path):\n",
    "        try:\n",
    "            gdf_cached = gpd.read_file(cache_path)\n",
    "            if not gdf_cached.empty:\n",
    "                print(f\"üü¢ Using cached {label} result for {cache_name} ({len(gdf_cached)} features)\")\n",
    "                return gdf_cached\n",
    "        except Exception:\n",
    "            print(f\"‚ö†Ô∏è Cache file {cache_name} unreadable, refetching...\")\n",
    "\n",
    "    # --- Prepare Overpass query ---\n",
    "    south, west, north, east = bbox\n",
    "    q = f\"\"\"\n",
    "    [out:json][timeout:{OVERPASS_TIMEOUT}];\n",
    "    (\n",
    "      {query_str}({south},{west},{north},{east});\n",
    "    );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "\n",
    "    attempt = 1\n",
    "    delay = INITIAL_BACKOFF\n",
    "    total_wait = 0\n",
    "    mirror_index = 0\n",
    "\n",
    "    while True:\n",
    "        url = OVERPASS_MIRRORS[mirror_index % len(OVERPASS_MIRRORS)]\n",
    "        print(f\"‚è≥ [{label}] Attempt {attempt} via {url} ...\")\n",
    "\n",
    "        try:\n",
    "            r = requests.post(url, data={\"data\": q}, timeout=OVERPASS_TIMEOUT)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            elements = data.get(\"elements\", [])\n",
    "\n",
    "            # --- Legitimate empty result (no retry) ---\n",
    "            if not elements:\n",
    "                print(f\"‚ÑπÔ∏è No {label} features found for {cache_name} (valid empty response).\")\n",
    "                empty_gdf = gpd.GeoDataFrame(columns=[\"geometry\"], crs=4326)\n",
    "                empty_gdf.to_file(cache_path, driver=\"GeoJSON\")\n",
    "                return empty_gdf\n",
    "\n",
    "            # --- Parse features ---\n",
    "            features = []\n",
    "            for el in elements:\n",
    "                if \"geometry\" in el and el[\"type\"] == \"way\":\n",
    "                    coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "                    features.append({\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": LineString(coords).__geo_interface__,\n",
    "                        \"properties\": {\"osmid\": el.get(\"id\")}\n",
    "                    })\n",
    "\n",
    "            gdf = gpd.GeoDataFrame.from_features(features, crs=\"EPSG:4326\")\n",
    "            gdf.to_file(cache_path, driver=\"GeoJSON\")\n",
    "            print(f\"‚úÖ [{label}] Success ({len(gdf)} features) ‚Äî cached as {cache_name}\")\n",
    "            return gdf\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"‚ö†Ô∏è [{label}] HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ö†Ô∏è [{label}] Network error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è [{label}] Unexpected error: {type(e).__name__}: {e}\")\n",
    "\n",
    "        # --- Retry logic ---\n",
    "        time.sleep(delay)\n",
    "        total_wait += delay / 60\n",
    "        delay = min(delay * 1.5, MAX_BACKOFF)\n",
    "        attempt += 1\n",
    "        mirror_index += 1  # rotate mirror\n",
    "\n",
    "        if total_wait > MAX_WAIT_MIN:\n",
    "            print(f\"‚ùå [{label}] Aborted after {MAX_WAIT_MIN} minutes total wait for {cache_name}\")\n",
    "            return gpd.GeoDataFrame(columns=[\"geometry\"], crs=4326)\n",
    "\n",
    "\n",
    "def dedup_geoms(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Remove duplicate OSM features across overlapping chunks.\"\"\"\n",
    "    if gdf.empty:\n",
    "        return gdf\n",
    "    before = len(gdf)\n",
    "    if \"osmid\" in gdf.columns:\n",
    "        gdf = gdf.drop_duplicates(subset=\"osmid\")\n",
    "    else:\n",
    "        gdf[\"wkt\"] = gdf.geometry.to_wkt()\n",
    "        gdf = gdf.drop_duplicates(subset=\"wkt\").drop(columns=\"wkt\")\n",
    "    after = len(gdf)\n",
    "    if before > after:\n",
    "        print(f\"‚ÑπÔ∏è Removed {before - after} duplicate geometries\")\n",
    "    return gdf.reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Prepare ride geometry\n",
    "# =============================================================================\n",
    "utm_crs = pick_utm_crs(gdf_line)\n",
    "line_utm = gdf_line.to_crs(utm_crs)\n",
    "total_len_m = line_utm.length.iloc[0]\n",
    "chunk_len_m = CHUNK_LEN_KM * 1000\n",
    "n_chunks = int(np.ceil(total_len_m / chunk_len_m))\n",
    "print(f\"Total ride {total_len_m/1000:.1f} km ‚Üí {n_chunks} chunks\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Prepare all points with distance along ride\n",
    "# =============================================================================\n",
    "pts_gdf = gpd.GeoDataFrame(pts, geometry=gpd.points_from_xy(pts.lon, pts.lat), crs=4326).to_crs(utm_crs)\n",
    "line_geom = line_utm.geometry.iloc[0]\n",
    "pts_gdf[\"dist_m\"] = pts_gdf.geometry.apply(line_geom.project)\n",
    "\n",
    "bridges_all, tunnels_all = [], []\n",
    "bbox_rects = []\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: Iterate through chunks and query Overpass (with caching)\n",
    "# =============================================================================\n",
    "for i in range(n_chunks):\n",
    "    start_d = max(0, i * chunk_len_m - OVERLAP_M)\n",
    "    end_d   = min((i + 1) * chunk_len_m + OVERLAP_M, total_len_m + END_PAD_M)\n",
    "\n",
    "    seg_pts = pts_gdf[(pts_gdf[\"dist_m\"] >= start_d) & (pts_gdf[\"dist_m\"] <= end_d)]\n",
    "    if seg_pts.empty:\n",
    "        print(f\"‚ö†Ô∏è Chunk {i+1} empty, skipping\")\n",
    "        continue\n",
    "\n",
    "    # true bbox of actual GPS points in this segment\n",
    "    minx, miny, maxx, maxy = seg_pts.total_bounds\n",
    "    pad = SEARCH_RADIUS_M * 2\n",
    "    minx -= pad; miny -= pad; maxx += pad; maxy += pad\n",
    "\n",
    "    bbox_wgs = gpd.GeoSeries([box(minx, miny, maxx, maxy)], crs=utm_crs).to_crs(4326).total_bounds\n",
    "    west, south, east, north = bbox_wgs\n",
    "    bbox = (south, west, north, east)\n",
    "    bbox_rects.append((west, south, east, north))\n",
    "\n",
    "    print(f\"\\n--- Chunk {i+1}/{n_chunks} ---\")\n",
    "    print(f\"lon[{west:.3f},{east:.3f}] lat[{south:.3f},{north:.3f}]\")\n",
    "\n",
    "    g_b = query_overpass_until_success(bbox, 'way[\"bridge\"=\"yes\"][\"highway\"]',\n",
    "                                       f\"bridges_chunk_{i+1:02}.geojson\", label=\"bridges\")\n",
    "    g_t = query_overpass_until_success(bbox, 'way[\"tunnel\"=\"yes\"][\"highway\"]',\n",
    "                                       f\"tunnels_chunk_{i+1:02}.geojson\", label=\"tunnels\")\n",
    "\n",
    "    if not g_b.empty: bridges_all.append(g_b)\n",
    "    if not g_t.empty: tunnels_all.append(g_t)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: Merge & deduplicate results\n",
    "# =============================================================================\n",
    "g_bridges = pd.concat(bridges_all, ignore_index=True) if bridges_all else gpd.GeoDataFrame(columns=[\"geometry\"], crs=4326)\n",
    "g_tunnels = pd.concat(tunnels_all, ignore_index=True) if tunnels_all else gpd.GeoDataFrame(columns=[\"geometry\"], crs=4326)\n",
    "\n",
    "g_bridges = dedup_geoms(g_bridges)\n",
    "g_tunnels = dedup_geoms(g_tunnels)\n",
    "\n",
    "# Filter to ride corridor\n",
    "buf_corridor = line_utm.buffer(SEARCH_RADIUS_M).to_crs(4326).geometry.iloc[0]\n",
    "if not g_bridges.empty:\n",
    "    g_bridges = g_bridges[g_bridges.intersects(buf_corridor)]\n",
    "if not g_tunnels.empty:\n",
    "    g_tunnels = g_tunnels[g_tunnels.intersects(buf_corridor)]\n",
    "\n",
    "print(f\"\\n‚úÖ Bridges in {SEARCH_RADIUS_M} m corridor: {len(g_bridges)} | tunnels: {len(g_tunnels)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: Map visualization\n",
    "# =============================================================================\n",
    "m = folium.Map(location=[pts[\"lat\"].mean(), pts[\"lon\"].mean()],\n",
    "               zoom_start=MAP_ZOOM_START,\n",
    "               tiles=MAP_TILE_STYLE)\n",
    "\n",
    "# Ride line\n",
    "folium.PolyLine(list(zip(pts[\"lat\"], pts[\"lon\"])),\n",
    "                color=\"red\", weight=3, opacity=0.9,\n",
    "                tooltip=f\"Ride: {pts['ride_id'].iloc[0]}\").add_to(m)\n",
    "\n",
    "# Corridor\n",
    "folium.GeoJson(buf_corridor.__geo_interface__,\n",
    "               style_function=lambda x: {\"color\": \"orange\", \"weight\": 1, \"fillOpacity\": 0.15}).add_to(m)\n",
    "\n",
    "# Chunk rectangles (light gray shading)\n",
    "for idx, (west, south, east, north) in enumerate(bbox_rects, start=1):\n",
    "    folium.Rectangle(\n",
    "        bounds=[[south, west], [north, east]],\n",
    "        color=\"#555555\",\n",
    "        fill=True,\n",
    "        fill_color=\"#999999\",\n",
    "        fill_opacity=0.35,\n",
    "        weight=1,\n",
    "        dash_array=\"4\",\n",
    "        tooltip=f\"Chunk {idx}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Bridges (blue)\n",
    "for g in g_bridges.geometry:\n",
    "    folium.GeoJson(g.__geo_interface__,\n",
    "                   style_function=lambda x: {\"color\": \"blue\", \"weight\": 3}).add_to(m)\n",
    "\n",
    "# Tunnels (green)\n",
    "for g in g_tunnels.geometry:\n",
    "    folium.GeoJson(g.__geo_interface__,\n",
    "                   style_function=lambda x: {\"color\": \"green\", \"weight\": 3}).add_to(m)\n",
    "\n",
    "# MiniMap\n",
    "plugins.MiniMap(toggle_display=True).add_to(m)\n",
    "\n",
    "# Save & open\n",
    "m.save(MAP_SAVE_PATH)\n",
    "import webbrowser; webbrowser.open(MAP_SAVE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
